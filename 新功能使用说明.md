# 新功能使用说明

本文档说明如何启用和使用两个新添加的功能：

1. **基于方向的音频增强方法**（SE模块）
2. **内容准确性评分功能**（评分模块）

---

## 功能1：基于方向的音频增强方法

### 功能说明

在 `se/models/beamformer.py` 中添加了 `directional_enhancement()` 方法，该方法能够：

- 自动检测语音来源方向（DOA - Direction of Arrival）
- 使用自适应MVDR波束形成针对性地增强该方向的音频
- 相比固定的波束形成，能够适应不同的语音位置

### 当前状态

**该功能已添加但未启用**。当前SE模块仍使用原有的处理流程（目前实际为直接通过，未使用波束形成）。

### 如何启用

#### 方法1：在 `se/raspberry_deploy.py` 中启用

找到 `process_audio()` 方法（约第277行），修改音频处理部分：

**原始代码（当前）：**
```python
# 当前代码直接通过音频，未使用增强
if np.issubdtype(chunk.dtype, np.integer):
    enhanced_float = chunk.astype(np.float32) / 32768.0
else:
    enhanced_float = chunk.astype(np.float32)

if enhanced_float.ndim > 1:
    enhanced_float = enhanced_float[:, 0]

final = np.clip(enhanced_float, -1.0, 1.0)
```

**修改为使用方向性增强：**
```python
# 步骤1：将音频转换为多通道格式 (channels, samples)
if enhanced_float.ndim == 1:
    # 如果是单通道，需要重新组织为多通道（假设6通道）
    # 注意：这需要实际的6通道输入数据
    # 如果只有单通道，需要确保 record_callback 正确处理多通道数据
    pass

# 步骤2：确保音频是多通道格式 (channels, samples)
if enhanced_float.ndim == 1:
    # 单通道情况：无法使用方向性增强，使用原有方法
    final = np.clip(enhanced_float, -1.0, 1.0)
else:
    # 多通道情况：使用方向性增强
    # 转换为 (channels, samples) 格式
    if enhanced_float.shape[0] < enhanced_float.shape[1]:
        enhanced_float = enhanced_float.T
    
    # 调用方向性增强方法
    enhanced = self.beamformer.directional_enhancement(enhanced_float)
    final = np.clip(enhanced, -1.0, 1.0)
```

**重要注意事项：**

1. **多通道数据要求**：该方法需要多通道音频输入（如6通道麦克风阵列）。如果当前使用单通道麦克风，需要：
   - 修改 `record_callback()` 方法以正确收集多通道数据
   - 或修改 `process_audio()` 中的数据处理逻辑

2. **性能考虑**：方向性增强包含DOA估计和自适应波束形成，计算量较大，可能影响实时性能。

3. **配置检查**：确保 `se/config.py` 中的 `MIC_POSITIONS` 配置正确，与实际麦克风阵列布局一致。

#### 方法2：在 `Beamformer` 类中直接调用

如果需要在其他地方使用，可以直接调用：

```python
from se.models.beamformer import Beamformer
from se.config import Config

# 初始化波束形成器
beamformer = Beamformer(
    mic_positions=Config.MIC_POSITIONS,
    fs=Config.SAMPLE_RATE,
    direction=Config.LOOK_DIRECTION
)

# 处理多通道音频 (channels, samples)
enhanced_audio = beamformer.directional_enhancement(multi_channel_audio, method='gcc_phat')
```

**参数说明：**
- `multi_channel_audio`: 多通道音频数组，形状为 `(channels, samples)`
- `method`: DOA估计方法，可选 `'gcc_phat'`（默认）或 `'srp_phat'`

---

## 功能2：内容准确性评分功能

### 功能说明

在 `scoring/content_accuracy_rater.py` 中添加了 `ContentAccuracyRater` 类，该类能够：

- 使用千问（Qwen）多模态大模型API评估回答的内容准确性
- **支持音频模态输入**：直接分析音频，无需预先转录
- 评估相关性（是否贴合题目、是否跑题）
- 评估逻辑性（能否自圆其说、逻辑是否清晰）
- 评估完整性（是否充分回答了问题）
- 评估内容质量（内容是否有意义、表达是否清晰）
- 提供详细的英文和中文反馈

### 当前状态

**该功能已添加但未启用**。当前评分系统仍使用原有的本地算法和讯飞评分。

### 如何启用

#### 前置条件

1. **安装DashScope库**（千问API SDK）：
```bash
pip install dashscope
```

2. **获取并设置API密钥**：
   - 访问 https://dashscope.console.aliyun.com/ 获取API密钥
   - 设置环境变量：
```bash
export DASHSCOPE_API_KEY="your-api-key-here"
```
或在代码中直接提供（不推荐，安全性较低）。

#### 步骤1：在 `scoring/speech_rater.py` 中集成

找到 `SpeechRater` 类的 `__init__` 方法（约第88行），添加初始化代码：

```python
# 尝试导入内容准确性评分器
try:
    from .content_accuracy_rater import ContentAccuracyRater
    self.content_accuracy_rater = ContentAccuracyRater()  # 使用默认模型 qwen-audio-turbo
    # 或指定模型: ContentAccuracyRater(model='qwen-audio-turbo')
except ImportError:
    self.content_accuracy_rater = None
    logger.warning("内容准确性评分器不可用")
```

#### 步骤2：在 `score()` 方法中调用

找到 `score()` 方法（约第113行），在计算完本地分数后添加内容准确性评估：

```python
def score(self, audio_path: str, text: str, 
          asr_confidence: Optional[float] = None,
          task_type: str = "independent",
          reference_text: Optional[str] = None) -> ScoreResult:
    # ... 现有代码 ...
    
    # 在计算完本地分数后，添加内容准确性评估
    content_accuracy_result = None
    if self.content_accuracy_rater and self.content_accuracy_rater.available:
        try:
            # 使用题目文本作为参考
            question_text = reference_text if reference_text else "General question"
            content_accuracy_result = self.content_accuracy_rater.score(
                audio_path=audio_path,
                question_text=question_text,
                recognized_text=text
            )
            logger.info(f"内容准确性评分: {content_accuracy_result['overall_score']:.2f}")
        except Exception as e:
            logger.error(f"内容准确性评分失败: {e}")
    
    # 如果得到内容准确性评分，可以将其融合到最终分数中
    if content_accuracy_result:
        # 方式1：加权融合到language_score
        accuracy_weight = 0.3  # 内容准确性权重
        language_weight = 0.7  # 原有语言评分权重
        
        accuracy_score = content_accuracy_result['overall_score']
        language_score = (language_score * language_weight + 
                         accuracy_score * accuracy_weight)
        
        # 方式2：或者直接在最终分数中融合
        # final_score = (final_score * 0.7 + accuracy_score * 4.0 * 0.3)
    
    # ... 继续现有代码 ...
```

#### 步骤3：在反馈生成中集成

可以在 `FeedbackGenerator` 中集成内容准确性反馈。找到 `scoring/feedback_generator.py`，在生成反馈时添加：

```python
# 如果有内容准确性评分结果，添加到反馈中
if content_accuracy_result:
    feedback_parts.append("\n内容准确性评估:")
    feedback_parts.append(f"相关性: {content_accuracy_result['relevance_score']:.2f}")
    feedback_parts.append(f"逻辑性: {content_accuracy_result['logic_score']:.2f}")
    feedback_parts.append(f"完整性: {content_accuracy_result['completeness_score']:.2f}")
    feedback_parts.append(content_accuracy_result['feedback_zh'])
```

#### 完整集成示例

在 `scoring/speech_rater.py` 的 `score()` 方法中，完整的修改示例：

```python
def score(self, audio_path: str, text: str, 
          asr_confidence: Optional[float] = None,
          task_type: str = "independent",
          reference_text: Optional[str] = None) -> ScoreResult:
    try:
        logger.info(f"开始评分: 音频={audio_path}, 文本长度={len(text)}")
        
        # ... 现有代码：计算本地分数 ...
        
        # === 新增：内容准确性评估 ===
        content_accuracy_result = None
        if self.content_accuracy_rater and self.content_accuracy_rater.available:
            try:
                question_text = reference_text if reference_text else "General question"
                content_accuracy_result = self.content_accuracy_rater.score(
                    audio_path=audio_path,
                    question_text=question_text,
                    recognized_text=text
                )
                
                # 融合到语言分数（可选）
                if 'overall_score' in content_accuracy_result:
                    accuracy_score = content_accuracy_result['overall_score']
                    # 加权融合：原有语言评分 70%，内容准确性 30%
                    language_score = language_score * 0.7 + accuracy_score * 0.3
                    logger.info(f"内容准确性评分已融合: {accuracy_score:.2f}")
            except Exception as e:
                logger.error(f"内容准确性评分失败: {e}")
        
        # ... 继续现有代码：计算最终分数、生成反馈 ...
        
        # 在反馈中包含内容准确性反馈（可选）
        if content_accuracy_result:
            feedback_en = feedback["en"] + "\n\nContent Accuracy: " + \
                         content_accuracy_result.get('feedback_en', '')
            feedback_zh = feedback["zh"] + "\n\n内容准确性: " + \
                         content_accuracy_result.get('feedback_zh', '')
            feedback = {"en": feedback_en, "zh": feedback_zh}
        
        # ... 返回结果 ...
```

### 配置选项

可以在 `scoring/config.py` 中添加配置：

```python
# 内容准确性评分配置
CONTENT_ACCURACY_CONFIG = {
    "enabled": False,  # 是否启用
    "api_key": os.getenv("DASHSCOPE_API_KEY"),  # DashScope API密钥（从环境变量读取）
    "model": "qwen-audio-turbo",  # 使用的模型（支持音频模态）
    "weight": 0.3,  # 在最终分数中的权重
}
```

然后在 `ContentAccuracyRater` 初始化时使用这些配置。

### 成本考虑

- OpenAI API调用会产生费用（按token计费）
- 建议在测试阶段使用，或添加缓存机制避免重复调用
- 可以考虑只在特定条件下启用（如分数接近边界值时）

---

## 注意事项

### 功能1（方向性增强）

1. **需要多通道音频输入**：该方法设计用于多通道麦克风阵列（如6通道）
2. **性能影响**：DOA估计和自适应波束形成计算量较大，可能影响实时性能
3. **配置要求**：需要正确配置麦克风位置（`MIC_POSITIONS`）

### 功能2（内容准确性评分）

1. **需要API密钥**：需要有效的DashScope API密钥（千问）
2. **网络连接**：需要网络连接访问API
3. **成本**：API调用会产生费用（按token计费，千问价格相对较低）
4. **延迟**：API调用会增加评分时间（通常1-3秒）
5. **音频模态优势**：直接使用音频输入，无需预先转录，可以更准确地评估语音内容

---

## 测试建议

### 测试功能1

```python
# 测试脚本
from se.models.beamformer import Beamformer
from se.config import Config
import numpy as np

# 创建测试数据（6通道，16000采样率，1秒）
test_audio = np.random.randn(6, 16000).astype(np.float32)

beamformer = Beamformer(
    mic_positions=Config.MIC_POSITIONS,
    fs=Config.SAMPLE_RATE,
    direction=0
)

enhanced = beamformer.directional_enhancement(test_audio)
print(f"输入形状: {test_audio.shape}, 输出形状: {enhanced.shape}")
```

### 测试功能2

```python
# 测试脚本
from scoring.content_accuracy_rater import ContentAccuracyRater

rater = ContentAccuracyRater()

if rater.available:
    result = rater.score(
        audio_path="test_audio.wav",
        question_text="Describe a person who has influenced you the most."
        # recognized_text 参数可选，主要使用音频模态
    )
    print(result)
else:
    print("内容准确性评分器不可用（请设置DASHSCOPE_API_KEY环境变量）")
```

---

## 总结

两个新功能都已添加到代码中，但默认**未启用**。如需使用，请按照上述步骤进行配置和集成。建议在测试环境中先验证功能是否正常工作，然后再集成到主流程中。
